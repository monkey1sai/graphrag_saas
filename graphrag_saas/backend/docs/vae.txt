Auto‑Encoding Variational Bayes proposes a stochastic variational inference algorithm for models with continuous latent variables. The approach builds on the variational autoencoder (VAE) framework, training a recognition model to approximate the posterior and enabling efficient inference and learning through stochastic gradient variational Bayes. The method is computationally efficient, requires little memory and is suitable for large‑scale problems. By leveraging the reparameterisation trick, the authors show that VAEs can be trained end‑to‑end using backpropagation.